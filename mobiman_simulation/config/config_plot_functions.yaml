save_path_rel: "dataset/analysis/"

action_time_horizon: 6.0

goal_range_min_x: -5.0
goal_range_max_x: 5.0

goal_range_min_y: -2.5
goal_range_max_y: 2.0

goal_range_min_z: 0.5
goal_range_max_z: 1.0

## Reward Function:
# Terminal:
reward_terminal_goal: 50
reward_terminal_collision: -10
reward_terminal_roll: -10
reward_terminal_max_step: -50

# Target-to-goal
reward_step_target2goal: 5
reward_step_target2goal_mu_regular: 2
reward_step_target2goal_sigma_regular: 2
reward_step_target2goal_mu_last_step: 0.75
reward_step_target2goal_sigma_last_step: 0.5

# Model mode
reward_step_mode0: -1.5
reward_step_mode1: -3.0
reward_step_mode2: -4.5

# MPC result
reward_step_mpc_exit: -5
reward_step_target_reached: 3
reward_step_time_horizon_min: -10
reward_step_time_horizon_max: 0

# Cost weights
alpha_step_target2goal: 1
alpha_step_mode: 1
alpha_step_mpc_result: 1