#### DRL Parameters 
#### NOTE: Be sure that -> drl_service_flag: true

### Common Parameters for Training and Testing
ros_pkg_name: "mobiman_simulation"
gazebo_robot_name: "mobiman"
mode: "training"
drl_data_path: "dataset/drl/"
initial_training_path: ""
training_log_name: "training_log"

### DRL-Training Parameters
world_name: "conveyor"
deep_learning_algorithm: "PPO"
motion_planning_algorithm: "ocs2"

# Options:
# mobiman_FC             -> FC(occupancy_set + target + prev_action)
# mobiman_2DCNN_FC       -> 2DCNN(Channel: 1, Height: occupancy_set, Width: time) + FC(CNN_output + target + prev_action)
observation_space_type: "mobiman_FC"

n_robot: 1

# Options:
# JackalJaco_mobiman_drl-v0
task_and_robot_environment_name: "JackalJaco_mobiman_drl-v00"

learning_rate: 0.0002
n_steps: 10 #1000
batch_size: 5 #50
ent_coef: 0.001
training_timesteps: 20 #10000
max_episode_steps: 10 #2000

training_checkpoint_freq: 10 #1000
plot_title: "Learning Curve"
plot_moving_average_window_size_timesteps: 20
plot_moving_average_window_size_episodes: 5

## Data and Sensors

world_frame_name: "world"
robot_frame_name: "base_link"
ee_frame_name: "j2n6s300_end_effector"
goal_frame_name: "grasp"

cmd_velocity_msg_name: "/cmd_vel"
occgrid_msg_name: "/occupancy_grid"
goal_status_msg_name: "/goal_status"
colsphere_msg_name: "/occupancy_distances"

occgrid_normalize_flag: True
occgrid_occ_min: 0
occgrid_occ_max: 100

#laser_size_downsampled: 90
#laser_normalize_flag: True
#laser_error_threshold: 0.1

## Algorithm: mobiman-DRL Parameters
# Action time horizon [s]
action_time_horizon: 8

# 0: Discrete
# 1: Continuous
action_type: 1

# IF action_type: 0 (Discrete)
# [baseMotion, armMotion, wholeBodyMotion]
n_action_model: 3

# [inputCost, targetCost, targetConstraint, selfCollisionConstraint, extCollisionConstraint, jointPositionConstraint, jointVelocityConstraint]
# [selfCollisionConstraint]
n_action_constraint: 1

# 32 fixed poses in robot workspace + 1 goal pose
n_action_target: 33 

# IF action_type: 1 (Continuous)
# [model(1), constraint(1), target(6)]
n_action: 8

goal_range_min: 0.25
goal_range_max: 10.0
collision_range_min: 0.25
collision_range_max: 2.0

n_obs_stack: 1
n_skip_obs_stack: 1

## Reward:
reward_terminal_success: 8
reward_step_scale: 0.5
penalty_terminal_fail: -5
penalty_cumulative_step: -5

### DRL-Testing Parameters
max_testing_episode_timesteps: 2000
max_testing_episodes: 2
goal_status_msg: "/goal_reaching_status"